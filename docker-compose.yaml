services:
  # Service OCR
  ocr-service:
    profiles: ["training", "prediction"]
    env_file:
    - path: ./.env
    image: killiankopp/ms-ocr-ia:1.3
    # le code source est dans ce repo: https://github.com/karned-kapla/ms-ocr-ia
    # l'hébergement DockerHub: https://hub.docker.com/r/killiankopp/ms-ocr-ia
    container_name: ocr-service
    ports:
      - ${DATA_INGESTION_PORT_OCR}:80
    networks:
      - sake

  # Service de nettoyage de texte
  clean-service:
    profiles: ["training", "prediction"]
    env_file:
    - path: ./.env
    image: killiankopp/sake-clean:2.0
    container_name: clean-service
    ports:
      - ${DATA_CLEANING_PORT_CLEAN_TEXT}:80
    networks:
      - sake

  # Service ETL
  etl-service:
    profiles: ["training", "prediction"]
    env_file:
    - path: ./.env
    image: killiankopp/sake-etl:2.0
    container_name: etl-service
    depends_on: # pour indiquer la dépendance des dockers (Lance ces dockers /!\ ça ne vérifie pas qu'ils soient prêts)
      - ocr-service
      - clean-service
    ports:
      - ${DATA_ETL_PORT_ETL}:80
    networks:
      - sake
    
  # Service de prétraitement
  preprocessing-service:
    profiles: ["training"]
    env_file:
    - path: ./.env
    image: belwen/sake-preprocessing:2.0
    container_name: preprocessing-service
    ports:
      - ${DATA_PREPROCESSING_PORT_PREPROCESSING}:80
    networks:
      - sake

  # Service d'entraînement
  train-service:
    profiles: ["training"]
    env_file:
    - path: ./.env
    image: belwen/sake-train:2.0
    container_name: train-service
    ports:
      - ${MODEL_TRAIN_PORT_TRAIN}:80
    networks:
      - sake

  # Service d'évaluation
  eval-service:
    profiles: ["training"]
    env_file:
    - path: ./.env
    image: belwen/sake-eval:2.0
    container_name: eval-service
    ports:
      - ${MODEL_EVAL_PORT_EVAL}:80
    networks:
      - sake

  # Service d'Orchestration
  predict-orchestrator-service:
    profiles: ["prediction"]
    env_file:
    - path: ./.env
    # image: killiankopp/sake-orchestrator:2.0
    image: killiankopp/sake-orchestrator:2.1
    container_name: predict-orchestrator-service
    depends_on: # pour indiquer la dépendance des dockers (Lance ces dockers /!\ ça ne vérifie pas qu'ils soient prêts)
      - etl-service
      - predict-service
    ports:
      - "${ORCHESTRATOR_PORT_ORCHESTRATOR}:80"
    networks:
      - sake
  
  # Service de prédiction
  predict-service:
    profiles: ["prediction"]
    env_file:
      - path: ./.env
    image: killiankopp/sake-predict:2.1  # Utilisation de l'image Docker spécifique
    container_name: predict-service
    ports:
      - "${PREDICT_PORT_PREDICT}:80"
    networks:
      - sake

  # Backend d'administration et gestion des données avec DVC et MLFLOW
  admin-backend-service:
    profiles: ["training"]
    env_file:
      - path: ./.env
    image: belwen/sake-admin-backend:2.1 
    container_name: admin-backend-service
    ports:
      - "${ADMIN_BACKEND_PORT}:80"
    networks:
      - sake

  # Streamlit d'administration, envoi des requêtes vers admin-backend-service
  admin-frontend-service:
    profiles: ["training"]
    env_file:
      - path: ./.env
    image: belwen/sake-admin-frontend:2.0  # Utilisation de l'image Docker spécifique
    container_name: admin-frontend-service
    ports:
      - "${ADMIN_FRONTEND_PORT}:80"
    networks:
      - sake

  # Prometheus Service
  prometheus-service:
    profiles: ["training", "prediction"]
    build:
      context: .
      dockerfile: docker/prometheus/Dockerfile
      args: 
        DOCKERFILE_DIR: docker/prometheus
    image: prometheus-service:1.0
    container_name: prometheus-service
    ports:
      - "9090:9090"
    networks:
      - sake

  alertmanager:
    profiles: ["training", "prediction"]
    build:
      context: .
      dockerfile: docker/alertmanager/Dockerfile
      args: 
        DOCKERFILE_DIR: docker/alertmanager
    image: alertmanager:1.0
    container_name: alertmanager
    ports:
      - "9093:9093"
    networks:
      - sake

  # Grafana Service
  grafana-service:
    profiles: ["training", "prediction"]
    build:
      context: docker/grafana/
      dockerfile: Dockerfile
      args: 
        DOCKERFILE_DIR: docker/grafana
    image: grafana-service:1.0
    container_name: grafana-service
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin  # Set the admin password
    ports:
      - "3000:80"
    networks:
      - sake
  
      
  node-exporter-service:
    profiles: ["training", "prediction"]
    image: prom/node-exporter:latest
    container_name: node-exporter-service
    networks:
      - sake
    ports:
      - "9100:9100"

  frontend-service:
    profiles: ["prediction"]
    env_file:
      - path: ./.env
    image: killiankopp/sake-frontend:2.1.2  # Utilisation de l'image Docker spécifique
    container_name: ms-sake-frontend
    ports:
      - "${FRONTEND_PORT_PREDICT}:80"
    networks:
      - sake

  file-service:
    profiles: ["training", "prediction"]
    env_file:
      - path: ./.env
    image: killiankopp/sake-file:2.0  # Utilisation de l'image Docker spécifique
    container_name: ms-sake-file
    ports:
      - "${FILE_PORT_PREDICT}:80"
    networks:
      - sake

networks:
  sake:
    driver: bridge  