services:
  # Service OCR
  ocr-service:
    profiles: ["training", "prediction"]
    env_file:
    - path: ./.env
    image: killiankopp/ms-ocr-ia:1.1
    # le code source est dans ce repo: https://github.com/karned-kapla/ms-ocr-ia
    # l'hébergement DockerHub: https://hub.docker.com/r/killiankopp/ms-ocr-ia
    container_name: ocr-service
    ports:
      - ${DATA_INGESTION_PORT_OCR}:80
    networks:
      - sake

  # Service de nettoyage de texte
  clean-service:
    profiles: ["training", "prediction"]
    env_file:
    - path: ./.env
    build:
      context: .  
      dockerfile: docker/clean_text/Dockerfile  
      args:
        COMMON_DIR: src
        SOURCE_DIR: src/data
        DOCKERFILE_DIR: docker/clean_text  
      cache_from: # pour force docker-compose à regarder le cache de ce docker (quand on utilise `docker-compose up --build`)
        - clean-service:cache
    image: clean-service:1.0
    container_name: clean-service
    ports:
      - ${DATA_CLEANING_PORT_CLEAN_TEXT}:80
    networks:
      - sake
    volumes: # /!\ les variables d'environnement UID et GID doivent être définies pour désigner le propriétaire hôte de ces volumes
      - ./${DATA_GENERAL_LOG_DIR}:/app/${DATA_GENERAL_LOG_DIR}

  # Service ETL
  etl-service:
    profiles: ["training", "prediction"]
    env_file:
    - path: ./.env
    build:
      context: .  
      dockerfile: docker/etl/Dockerfile  
      args:
        COMMON_DIR: src
        SOURCE_DIR: src/data
        DOCKERFILE_DIR: docker/etl  
      cache_from: # pour force docker-compose à regarder le cache de ce docker (quand on utilise `docker-compose up --build`)
        - etl-service:cache  
    image: etl-service:1.0
    container_name: etl-service
    depends_on: # pour indiquer la dépendance des dockers (Lance ces dockers /!\ ça ne vérifie pas qu'ils soient prêts)
      - ocr-service
      - clean-service
    ports:
      - ${DATA_ETL_PORT_ETL}:80
    networks:
      - sake
    volumes: # /!\ les variables d'environnement UID et GID doivent être définies pour désigner le propriétaire hôte de ces volumes
      - ./${DATA_STRUCTURE_RAW_RAW_DATASET_DIR}:/app/${DATA_STRUCTURE_RAW_RAW_DATASET_DIR}
      - ./${DATA_INGESTION_OCR_TEXT_DIR}:/app/${DATA_INGESTION_OCR_TEXT_DIR}
      - ./${DATA_CLEANING_CLEANED_DATASETS_DIR}:/app/${DATA_CLEANING_CLEANED_DATASETS_DIR}
      - ./${DATA_GENERAL_LOG_DIR}:/app/${DATA_GENERAL_LOG_DIR}
    
  # Service de prétraitement
  preprocessing-service:
    profiles: ["training"]
    env_file:
    - path: ./.env
    build:
      context: .  
      dockerfile: docker/preprocessing/Dockerfile  
      args:
        COMMON_DIR: src
        SOURCE_DIR: src/preprocessing
        DOCKERFILE_DIR: docker/preprocessing
      cache_from: # pour force docker-compose à regarder le cache de ce docker (quand on utilise `docker-compose up --build`)
        - preprocessing-service:cache
    image: preprocessing-service:1.0
    container_name: preprocessing-service
    ports:
      - ${DATA_PREPROCESSING_PORT_PREPROCESSING}:80
    networks:
      - sake
    volumes: # /!\ les variables d'environnement UID et GID doivent être définies pour désigner le propriétaire hôte de ces volumes
      - ./${DATA_CLEANING_CLEANED_DATASETS_DIR}:/app/${DATA_CLEANING_CLEANED_DATASETS_DIR}
      - ./${DATA_PREPROCESSING_PREPROCESSED_DATA_DIR}:/app/${DATA_PREPROCESSING_PREPROCESSED_DATA_DIR}
      - ./${DATA_PREPROCESSING_MODELS_DIR}:/app/${DATA_PREPROCESSING_MODELS_DIR}
      - ./${DATA_GENERAL_LOG_DIR}:/app/${DATA_GENERAL_LOG_DIR}

  # Service d'entraînement
  train-service:
    profiles: ["training"]
    env_file:
    - path: ./.env
    build:
      context: .  
      dockerfile: docker/train/Dockerfile  
      args:
        COMMON_DIR: src
        SOURCE_DIR: src/train
        DOCKERFILE_DIR: docker/train
      cache_from: # pour force docker-compose à regarder le cache de ce docker (quand on utilise `docker-compose up --build`)
        - train-service:cache
    image: train-service:1.0
    container_name: train-service
    ports:
      - ${MODEL_TRAIN_PORT_TRAIN}:80
    networks:
      - sake
    volumes: # /!\ les variables d'environnement UID et GID doivent être définies pour désigner le propriétaire hôte de ces volumes
      - ./${DATA_PREPROCESSING_PREPROCESSED_DATA_DIR}:/app/${DATA_PREPROCESSING_PREPROCESSED_DATA_DIR}
      - ./${DATA_PREPROCESSING_MODELS_DIR}:/app/${DATA_PREPROCESSING_MODELS_DIR}
      - ./${DATA_GENERAL_LOG_DIR}:/app/${DATA_GENERAL_LOG_DIR}

  # Service d'évaluation
  eval-service:
    profiles: ["training"]
    env_file:
    - path: ./.env
    build:
      context: .  
      dockerfile: docker/eval/Dockerfile  
      args:
        COMMON_DIR: src
        SOURCE_DIR: src/eval
        DOCKERFILE_DIR: docker/eval
      cache_from: # pour force docker-compose à regarder le cache de ce docker (quand on utilise `docker-compose up --build`)
        - eval-service:cache
    image: eval-service:1.0
    container_name: eval-service
    ports:
      - ${MODEL_EVAL_PORT_EVAL}:80
    networks:
      - sake
    volumes: # /!\ les variables d'environnement UID et GID doivent être définies pour désigner le propriétaire hôte de ces volumes
      - ./${DATA_PREPROCESSING_PREPROCESSED_DATA_DIR}:/app/${DATA_PREPROCESSING_PREPROCESSED_DATA_DIR}
      - ./${DATA_PREPROCESSING_MODELS_DIR}:/app/${DATA_PREPROCESSING_MODELS_DIR}
      - ./${MODEL_EVAL_METRICS_DIR}:/app/${MODEL_EVAL_METRICS_DIR}
      - ./${DATA_GENERAL_LOG_DIR}:/app/${DATA_GENERAL_LOG_DIR}
      - ./${DATA_CLEANING_CLEANED_DATASETS_DIR}:/app/${DATA_CLEANING_CLEANED_DATASETS_DIR}

  # Service d'Orchestration
  predict-orchestrator-service:
    profiles: ["prediction"]
    env_file:
    - path: ./.env
    build:
      context: .  
      dockerfile: docker/orchestrator/Dockerfile  
      args:
        SOURCE_DIR: src/
        DOCKERFILE_DIR: docker/orchestrator
        LOG_DIR: src
      cache_from: # pour force docker-compose à regarder le cache de ce docker (quand on utilise `docker-compose up --build`)
        - predict-orchestrator:cache
    image: predict-orchestrator:1.0  
    container_name: predict-orchestrator
    depends_on: # pour indiquer la dépendance des dockers (Lance ces dockers /!\ ça ne vérifie pas qu'ils soient prêts)
      - etl-service
      - predict-service
    ports:
      - "${ORCHESTRATOR_PORT_ORCHESTRATOR}:80"
    networks:
      - sake
  
  # Service de prédiction
  predict-service:
    profiles: ["prediction"]
    env_file:
    - path: ./.env
    build:
      context: .  
      dockerfile: docker/predict/Dockerfile  
      args:
        SOURCE_DIR: src/
        DOCKERFILE_DIR: docker/predict
        LOG_DIR: src
        MODELS_DIR: models/
      cache_from: # pour force docker-compose à regarder le cache de ce docker (quand on utilise `docker-compose up --build`)
        - ms-sake-predict:cache
    image: ms-sake-predict:1.0  
    container_name: ms-sake-predict
    ports:
      - "${PREDICT_PORT_PREDICT}:80"
    networks:
      - sake

  # Streamlit admin et gestion des données avec DVC et MLFLOW
  admin-service:
    profiles: ["training"]
    env_file:
    - path: ./.env
    build:
      context: .  
      dockerfile: docker/admin/Dockerfile  
      args:
        COMMON_DIR: src
        SOURCE_DIR: src/admin
        DOCKERFILE_DIR: docker/admin
        STREAMLIT_DIR: src/streamlit
        DAGSHUB_ACCESS_KEY_ID: ${DAGSHUB_ACCESS_KEY_ID}
      cache_from: # pour force docker-compose à regarder le cache de ce docker (quand on utilise `docker-compose up --build`)
        - admin-service:cache
    image: admin-service:1.0  
    container_name: admin-service
    ports:
      - "${ADMIN_PORT_ADMIN}:80"
    networks:
      - sake
    volumes:
      - ./${DATA_PREPROCESSING_MODELS_DIR}:/app/SEP24-MLOPS-SAKE/${DATA_PREPROCESSING_MODELS_DIR}
      - ./${MODEL_EVAL_METRICS_DIR}:/app/SEP24-MLOPS-SAKE/${MODEL_EVAL_METRICS_DIR}
      - ./${DATA_STRUCTURE_RAW_RAW_DATASET_DIR}:/app/SEP24-MLOPS-SAKE/${DATA_STRUCTURE_RAW_RAW_DATASET_DIR}
      - ./${DATA_INGESTION_OCR_TEXT_DIR}:/app/SEP24-MLOPS-SAKE/${DATA_INGESTION_OCR_TEXT_DIR}
      - ./${DATA_CLEANING_CLEANED_DATASETS_DIR}:/app/SEP24-MLOPS-SAKE/${DATA_CLEANING_CLEANED_DATASETS_DIR}
      - ./${DATA_GENERAL_LOG_DIR}:/app/SEP24-MLOPS-SAKE/${DATA_GENERAL_LOG_DIR}

  # Prometheus Service
  prometheus-service:
    profiles: ["training", "prediction"]
    build:
      context: .
      dockerfile: docker/prometheus/Dockerfile
      args: 
        DOCKERFILE_DIR: docker/prometheus
    image: prometheus-service:1.0
    container_name: prometheus-service
    ports:
      - "9090:9090"
    networks:
      - sake

  # Grafana Service
  grafana-service:
    profiles: ["training", "prediction"]
    build:
      context: .
      dockerfile: docker/grafana/Dockerfile
      args: 
        DOCKERFILE_DIR: docker/grafana
    image: grafana-service:1.0
    container_name: grafana-service
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin  # Set the admin password
    ports:
      - "3000:3000"
    networks:
      - sake
      
  node-exporter-service:
    profiles: ["training", "prediction"]
    image: prom/node-exporter:latest
    container_name: node-exporter-service
    networks:
      - sake
    ports:
      - "9100:9100"


networks:
  sake:
    driver: bridge  